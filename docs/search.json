[
  {
    "objectID": "nm-hyperparameter-tuning.html",
    "href": "nm-hyperparameter-tuning.html",
    "title": "ESS330: Lab 8 - Hyperparameter Tuning QMD",
    "section": "",
    "text": "library(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.4.3\n\n\nWarning: package 'ggplot2' was built under R version 4.4.3\n\n\nWarning: package 'tidyr' was built under R version 4.4.3\n\n\nWarning: package 'readr' was built under R version 4.4.3\n\n\nWarning: package 'purrr' was built under R version 4.4.3\n\n\nWarning: package 'dplyr' was built under R version 4.4.3\n\n\nWarning: package 'lubridate' was built under R version 4.4.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\nWarning: package 'tidymodels' was built under R version 4.4.3\n\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.3.0 ──\n✔ broom        1.0.8     ✔ rsample      1.2.1\n✔ dials        1.4.0     ✔ tune         1.3.0\n✔ infer        1.0.7     ✔ workflows    1.2.0\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.3.1     ✔ yardstick    1.3.2\n✔ recipes      1.1.1     \n\n\nWarning: package 'broom' was built under R version 4.4.3\n\n\nWarning: package 'dials' was built under R version 4.4.3\n\n\nWarning: package 'parsnip' was built under R version 4.4.3\n\n\nWarning: package 'recipes' was built under R version 4.4.3\n\n\nWarning: package 'tune' was built under R version 4.4.3\n\n\nWarning: package 'workflows' was built under R version 4.4.3\n\n\nWarning: package 'yardstick' was built under R version 4.4.3\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n\nlibrary(glue)\n\nWarning: package 'glue' was built under R version 4.4.3\n\nlibrary(dplyr)\nlibrary(powerjoin)\n\nWarning: package 'powerjoin' was built under R version 4.4.3\n\nlibrary(skimr)\n\nWarning: package 'skimr' was built under R version 4.4.3\n\nlibrary(visdat)\n\nWarning: package 'visdat' was built under R version 4.4.3\n\nlibrary(ggpubr)\n\nWarning: package 'ggpubr' was built under R version 4.4.3\n\nlibrary(recipes)\n##Lets return to the CAMELS dataset we have been working with in Lab 6. We will use this dataset to predict the q_mean variable using the other variables in the dataset.\n#Reading in Data - Data Import/Tidy/Transform\n\nroot  &lt;- 'https://gdex.ucar.edu/dataset/camels/file'\n\ntypes &lt;- c(\"clim\", \"geol\", \"soil\", \"topo\", \"vege\", \"hydro\")\n\nremote_files &lt;- glue(\n  '{root}/camels_{types}.txt')\n\nlocal_files &lt;- glue(\n  'data/camels_{types}.txt')\n\n\nwalk2(remote_files, local_files, download.file, quiet = TRUE)\n\ncamels_8 &lt;- map(local_files, read_delim, show_col_types = FALSE) \n\ncamels_8 &lt;- power_full_join(camels_8 ,by = 'gauge_id')"
  },
  {
    "objectID": "nm-hyperparameter-tuning.html#data-splitting",
    "href": "nm-hyperparameter-tuning.html#data-splitting",
    "title": "ESS330: Lab 8 - Hyperparameter Tuning QMD",
    "section": "Data Splitting",
    "text": "Data Splitting\n\nset.seed(456)\n\ncam8_split &lt;- initial_split(camels_8, prop = 0.80)\n\ncam8_train &lt;- training(cam8_split)\n\ncam8_test &lt;- testing(cam8_split)\n\ncam8_cv &lt;- vfold_cv(cam8_train, v = 10)"
  },
  {
    "objectID": "nm-hyperparameter-tuning.html#feature-engineering",
    "href": "nm-hyperparameter-tuning.html#feature-engineering",
    "title": "ESS330: Lab 8 - Hyperparameter Tuning QMD",
    "section": "Feature Engineering",
    "text": "Feature Engineering\n\n#Building the Recipe\n\nrec_8 &lt;- recipe(logQmean ~ aridity + p_mean, data = cam8_train) %&gt;%\n  step_log(all_predictors()) %&gt;%\n  step_interact(terms = ~ aridity:p_mean) %&gt;%\n  step_novel(all_nominal_predictors()) %&gt;%\n  step_unknown(all_nominal_predictors()) %&gt;%\n  step_naomit(all_predictors(), all_outcomes())\n\n  \n#Baking the data\n\ncam8_baked &lt;- prep(rec_8, cam8_train) |&gt;\n  bake(new_data = NULL)"
  },
  {
    "objectID": "nm-hyperparameter-tuning.html#resampling-and-model-testing",
    "href": "nm-hyperparameter-tuning.html#resampling-and-model-testing",
    "title": "ESS330: Lab 8 - Hyperparameter Tuning QMD",
    "section": "Resampling and Model Testing",
    "text": "Resampling and Model Testing\n\n# 1. Building Resamples\n\ncam8_cv &lt;- vfold_cv(cam8_train, v = 10)\n\n\n# 2. Build 3 Candidate Models\n\n## a. Linear Model\nlm8_mod &lt;- linear_reg() %&gt;%\n  set_engine('lm') %&gt;%\n  set_mode(\"regression\")\n\nlm8_wf &lt;- workflow() %&gt;%\n  add_recipe(rec_8) %&gt;%\n  add_model(lm8_mod) %&gt;%\n  fit(data = cam8_train)\n\n## b. Random Forest\nrf8_mod &lt;- rand_forest() %&gt;%\n  set_engine('ranger') %&gt;%\n  set_mode(\"regression\")\n\nrf8_wf &lt;- workflow() %&gt;%\n  add_recipe(rec_8) %&gt;%\n  add_model(rf8_mod) %&gt;%\n  fit(data = cam8_train)\n\n## c. Boost Model\nb8_mod &lt;- boost_tree() %&gt;%\n  set_engine('xgboost') %&gt;%\n  set_mode(\"regression\")\n\nb8_wf &lt;- workflow() %&gt;%\n  add_recipe(rec_8) %&gt;%\n  add_model(b8_mod) %&gt;%\n  fit(data = cam8_train)\n\n\n# 3. Testing the Models\n\nwf8 &lt;- workflow_set(list(rec_8), list(lm8_mod, rf8_mod, b8_mod)) %&gt;%\n  workflow_map('fit_resamples', resamples = cam8_cv)\n\nWarning: package 'ranger' was built under R version 4.4.3\n\n\nWarning: package 'xgboost' was built under R version 4.4.3\n\nautoplot(wf8)\n\n\n\n\n\n\n\nrank_results(wf8, rank_metric = \"rmse\", select_best = TRUE)\n\n# A tibble: 6 × 9\n  wflow_id          .config .metric  mean std_err     n preprocessor model  rank\n  &lt;chr&gt;             &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;        &lt;chr&gt; &lt;int&gt;\n1 recipe_rand_fore… Prepro… rmse    0.540  0.0199    10 recipe       rand…     1\n2 recipe_rand_fore… Prepro… rsq     0.778  0.0220    10 recipe       rand…     1\n3 recipe_linear_reg Prepro… rmse    0.541  0.0179    10 recipe       line…     2\n4 recipe_linear_reg Prepro… rsq     0.781  0.0155    10 recipe       line…     2\n5 recipe_boost_tree Prepro… rmse    0.569  0.0191    10 recipe       boos…     3\n6 recipe_boost_tree Prepro… rsq     0.754  0.0245    10 recipe       boos…     3\n\n#We can see that the random forest model performed better for both mapping the rsq and rmse.Since the random forest model had the lowest RMSE (0.527) and the highest Rsq (0.788) across the 10 resamples, this showed that it would be able to make more accurate predictions than the linear and xgboost models we tested in our workflow set. \n\n# I selected the model Random Forest, using the 'ranger' engine, and a \"regression\" mode. The reason this combination of model testers works better for a large dataset like CAMELS is because Random forest handles nonlinearitys and interactions by using my computer's native software. As we have learned in class this Random Forests are also able to handle variable importance predictors, so irrelevant variables have less influence, making it less prone to overfitting."
  },
  {
    "objectID": "nm-hyperparameter-tuning.html#model-tuning",
    "href": "nm-hyperparameter-tuning.html#model-tuning",
    "title": "ESS330: Lab 8 - Hyperparameter Tuning QMD",
    "section": "Model Tuning",
    "text": "Model Tuning\n\n# 1. Build a Model\n\nrf8m_tune &lt;- rand_forest(\n  mtry = tune(),\n  min_n = tune()\n) %&gt;%\n  set_engine('ranger') %&gt;%\n  set_mode(\"regression\")\n\n\n# 2. Create a Workflow\n\nrf8wf_tune &lt;- workflow() %&gt;%\n  add_recipe(rec_8) %&gt;%\n  add_model(rf8m_tune)\n\n\n# 3. Check the Tunable Values/Ranges\n\ndials &lt;- extract_parameter_set_dials(rf8wf_tune)\n\n# Ensure it's a parameters object by checking it\nprint(dials)\n\nCollection of 2 parameters for tuning\n\n\n\n\n\n identifier  type    object\n       mtry  mtry nparam[?]\n      min_n min_n nparam[+]\n\n\n\n\n\nModel parameters needing finalization:\n\n\n# Randomly Selected Predictors ('mtry')\n\n\n\n\n\nSee `?dials::finalize()` or `?dials::update.parameters()` for more information.\n\nparams &lt;- dials$object\n\n# 4. Define the Search Space\nparams &lt;- finalize(params, cam8_train)\n\nmy.grid &lt;- grid_latin_hypercube(\n  params,\n  size = 25\n)\n\nWarning: `grid_latin_hypercube()` was deprecated in dials 1.3.0.\nℹ Please use `grid_space_filling()` instead.\n\n# 5. Tune the Model\n\nmodel_params &lt;-  tune_grid(\n    rf8wf_tune,\n    resamples = cam8_cv,\n    grid = my.grid,\n    metrics = metric_set(rmse, rsq, mae),\n    control = control_grid(save_pred = TRUE)\n  )\n\n→ A | warning: ! 27 columns were requested but there were 3 predictors in the data.\n               ℹ 3 predictors will be used.\n\n\nThere were issues with some computations   A: x1\n\n\n→ B | warning: ! 42 columns were requested but there were 3 predictors in the data.\n               ℹ 3 predictors will be used.\n\n\nThere were issues with some computations   A: x1\n→ C | warning: ! 34 columns were requested but there were 3 predictors in the data.\n               ℹ 3 predictors will be used.\nThere were issues with some computations   A: x1\n→ D | warning: ! 56 columns were requested but there were 3 predictors in the data.\n               ℹ 3 predictors will be used.\nThere were issues with some computations   A: x1\n→ E | warning: ! 37 columns were requested but there were 3 predictors in the data.\n               ℹ 3 predictors will be used.\nThere were issues with some computations   A: x1\n→ F | warning: ! 6 columns were requested but there were 3 predictors in the data.\n               ℹ 3 predictors will be used.\nThere were issues with some computations   A: x1\n→ G | warning: ! 19 columns were requested but there were 3 predictors in the data.\n               ℹ 3 predictors will be used.\nThere were issues with some computations   A: x1\n→ H | warning: ! 22 columns were requested but there were 3 predictors in the data.\n               ℹ 3 predictors will be used.\nThere were issues with some computations   A: x1\nThere were issues with some computations   A: x1   B: x1   C: x1   D: x1   E: x…\n→ I | warning: ! 49 columns were requested but there were 3 predictors in the data.\n               ℹ 3 predictors will be used.\nThere were issues with some computations   A: x1   B: x1   C: x1   D: x1   E: x…\n→ J | warning: ! 30 columns were requested but there were 3 predictors in the data.\n                ℹ 3 predictors will be used.\nThere were issues with some computations   A: x1   B: x1   C: x1   D: x1   E: x…\n→ K | warning: ! 32 columns were requested but there were 3 predictors in the data.\n                ℹ 3 predictors will be used.\nThere were issues with some computations   A: x1   B: x1   C: x1   D: x1   E: x…\n→ L | warning: ! 45 columns were requested but there were 3 predictors in the data.\n                ℹ 3 predictors will be used.\nThere were issues with some computations   A: x1   B: x1   C: x1   D: x1   E: x…\n→ M | warning: ! 57 columns were requested but there were 3 predictors in the data.\n                ℹ 3 predictors will be used.\nThere were issues with some computations   A: x1   B: x1   C: x1   D: x1   E: x…\n→ N | warning: ! 52 columns were requested but there were 3 predictors in the data.\n                ℹ 3 predictors will be used.\nThere were issues with some computations   A: x1   B: x1   C: x1   D: x1   E: x…\n→ O | warning: ! 12 columns were requested but there were 3 predictors in the data.\n                ℹ 3 predictors will be used.\nThere were issues with some computations   A: x1   B: x1   C: x1   D: x1   E: x…\n→ P | warning: ! 14 columns were requested but there were 3 predictors in the data.\n                ℹ 3 predictors will be used.\nThere were issues with some computations   A: x1   B: x1   C: x1   D: x1   E: x…\n→ Q | warning: ! 47 columns were requested but there were 3 predictors in the data.\n                ℹ 3 predictors will be used.\nThere were issues with some computations   A: x1   B: x1   C: x1   D: x1   E: x…\n→ R | warning: ! 10 columns were requested but there were 3 predictors in the data.\n                ℹ 3 predictors will be used.\nThere were issues with some computations   A: x1   B: x1   C: x1   D: x1   E: x…\n→ S | warning: ! 15 columns were requested but there were 3 predictors in the data.\n                ℹ 3 predictors will be used.\nThere were issues with some computations   A: x1   B: x1   C: x1   D: x1   E: x…\n→ T | warning: ! 25 columns were requested but there were 3 predictors in the data.\n                ℹ 3 predictors will be used.\nThere were issues with some computations   A: x1   B: x1   C: x1   D: x1   E: x…\n→ U | warning: ! 39 columns were requested but there were 3 predictors in the data.\n                ℹ 3 predictors will be used.\nThere were issues with some computations   A: x1   B: x1   C: x1   D: x1   E: x…\nThere were issues with some computations   A: x1   B: x1   C: x1   D: x1   E: x…\n→ V | warning: ! 50 columns were requested but there were 3 predictors in the data.\n                ℹ 3 predictors will be used.\nThere were issues with some computations   A: x1   B: x1   C: x1   D: x1   E: x…\nThere were issues with some computations   A: x2   B: x2   C: x2   D: x2   E: x…\nThere were issues with some computations   A: x3   B: x3   C: x3   D: x3   E: x…\nThere were issues with some computations   A: x3   B: x3   C: x3   D: x3   E: x…\nThere were issues with some computations   A: x4   B: x4   C: x4   D: x4   E: x…\nThere were issues with some computations   A: x5   B: x5   C: x5   D: x5   E: x…\nThere were issues with some computations   A: x5   B: x5   C: x5   D: x5   E: x…\nThere were issues with some computations   A: x6   B: x6   C: x6   D: x6   E: x…\nThere were issues with some computations   A: x7   B: x7   C: x7   D: x7   E: x…\nThere were issues with some computations   A: x7   B: x7   C: x7   D: x7   E: x…\nThere were issues with some computations   A: x8   B: x8   C: x8   D: x8   E: x…\nThere were issues with some computations   A: x9   B: x9   C: x9   D: x9   E: x…\nThere were issues with some computations   A: x9   B: x9   C: x9   D: x9   E: x…\nThere were issues with some computations   A: x10   B: x10   C: x10   D: x10   …\nThere were issues with some computations   A: x10   B: x10   C: x10   D: x10   …\n\nautoplot(model_params)\n\n\n\n\n\n\n\n### From this graph I can see that as we increase the randomly selected predictor values: MAE, RMSE, and RSQ all increase in their ability to fit the model to the data better, with 60 being the maximum and best model fit number. We can see that as we use more predictors at each split, this will improve the accruacy overall of the random forest model used on the CAMELS dataset. ALTHOUGH, as we turn our attention towards the Minimal Node size, we can see there isn't a clear trend regarding the data, however, the data appears to be more balanced between 10-20 nodes with a similar trend for MAE, RMSE, and RSQ.\n\n\n# 6. Check the Skill of the Tuned Model\n\ntuned_results &lt;- tune_grid(\n  rf8wf_tune,\n  resamples = cam8_cv,\n  grid = my.grid,\n  metrics = metric_set(mae, rmse, rsq),\n  control = control_grid(save_pred = TRUE)\n)\n\n→ A | warning: ! 27 columns were requested but there were 3 predictors in the data.\n               ℹ 3 predictors will be used.\n→ B | warning: ! 42 columns were requested but there were 3 predictors in the data.\n               ℹ 3 predictors will be used.\n→ C | warning: ! 34 columns were requested but there were 3 predictors in the data.\n               ℹ 3 predictors will be used.\n→ D | warning: ! 56 columns were requested but there were 3 predictors in the data.\n               ℹ 3 predictors will be used.\n→ E | warning: ! 37 columns were requested but there were 3 predictors in the data.\n               ℹ 3 predictors will be used.\nThere were issues with some computations   A: x1   B: x1   C: x1   D: x1   E: x1\n→ F | warning: ! 6 columns were requested but there were 3 predictors in the data.\n               ℹ 3 predictors will be used.\nThere were issues with some computations   A: x1   B: x1   C: x1   D: x1   E: x1\n→ G | warning: ! 19 columns were requested but there were 3 predictors in the data.\n               ℹ 3 predictors will be used.\nThere were issues with some computations   A: x1   B: x1   C: x1   D: x1   E: x1\n→ H | warning: ! 22 columns were requested but there were 3 predictors in the data.\n               ℹ 3 predictors will be used.\nThere were issues with some computations   A: x1   B: x1   C: x1   D: x1   E: x1\n→ I | warning: ! 49 columns were requested but there were 3 predictors in the data.\n               ℹ 3 predictors will be used.\nThere were issues with some computations   A: x1   B: x1   C: x1   D: x1   E: x1\n→ J | warning: ! 30 columns were requested but there were 3 predictors in the data.\n                ℹ 3 predictors will be used.\nThere were issues with some computations   A: x1   B: x1   C: x1   D: x1   E: x1\n→ K | warning: ! 32 columns were requested but there were 3 predictors in the data.\n                ℹ 3 predictors will be used.\nThere were issues with some computations   A: x1   B: x1   C: x1   D: x1   E: x1\n→ L | warning: ! 45 columns were requested but there were 3 predictors in the data.\n                ℹ 3 predictors will be used.\nThere were issues with some computations   A: x1   B: x1   C: x1   D: x1   E: x1\n→ M | warning: ! 57 columns were requested but there were 3 predictors in the data.\n                ℹ 3 predictors will be used.\nThere were issues with some computations   A: x1   B: x1   C: x1   D: x1   E: x1\n→ N | warning: ! 52 columns were requested but there were 3 predictors in the data.\n                ℹ 3 predictors will be used.\nThere were issues with some computations   A: x1   B: x1   C: x1   D: x1   E: x1\n→ O | warning: ! 12 columns were requested but there were 3 predictors in the data.\n                ℹ 3 predictors will be used.\nThere were issues with some computations   A: x1   B: x1   C: x1   D: x1   E: x1\n→ P | warning: ! 14 columns were requested but there were 3 predictors in the data.\n                ℹ 3 predictors will be used.\nThere were issues with some computations   A: x1   B: x1   C: x1   D: x1   E: x1\n→ Q | warning: ! 47 columns were requested but there were 3 predictors in the data.\n                ℹ 3 predictors will be used.\nThere were issues with some computations   A: x1   B: x1   C: x1   D: x1   E: x1\nThere were issues with some computations   A: x1   B: x1   C: x1   D: x1   E: x…\n→ R | warning: ! 10 columns were requested but there were 3 predictors in the data.\n                ℹ 3 predictors will be used.\nThere were issues with some computations   A: x1   B: x1   C: x1   D: x1   E: x…\n→ S | warning: ! 15 columns were requested but there were 3 predictors in the data.\n                ℹ 3 predictors will be used.\nThere were issues with some computations   A: x1   B: x1   C: x1   D: x1   E: x…\n→ T | warning: ! 25 columns were requested but there were 3 predictors in the data.\n                ℹ 3 predictors will be used.\nThere were issues with some computations   A: x1   B: x1   C: x1   D: x1   E: x…\n→ U | warning: ! 39 columns were requested but there were 3 predictors in the data.\n                ℹ 3 predictors will be used.\nThere were issues with some computations   A: x1   B: x1   C: x1   D: x1   E: x…\n→ V | warning: ! 50 columns were requested but there were 3 predictors in the data.\n                ℹ 3 predictors will be used.\nThere were issues with some computations   A: x1   B: x1   C: x1   D: x1   E: x…\nThere were issues with some computations   A: x2   B: x2   C: x2   D: x2   E: x…\nThere were issues with some computations   A: x3   B: x2   C: x2   D: x2   E: x…\nThere were issues with some computations   A: x3   B: x3   C: x3   D: x3   E: x…\nThere were issues with some computations   A: x4   B: x4   C: x4   D: x4   E: x…\nThere were issues with some computations   A: x5   B: x5   C: x5   D: x4   E: x…\nThere were issues with some computations   A: x5   B: x5   C: x5   D: x5   E: x…\nThere were issues with some computations   A: x6   B: x6   C: x6   D: x6   E: x…\nThere were issues with some computations   A: x7   B: x7   C: x7   D: x6   E: x…\nThere were issues with some computations   A: x7   B: x7   C: x7   D: x7   E: x…\nThere were issues with some computations   A: x8   B: x8   C: x8   D: x8   E: x…\nThere were issues with some computations   A: x9   B: x9   C: x9   D: x9   E: x…\nThere were issues with some computations   A: x9   B: x9   C: x9   D: x9   E: x…\nThere were issues with some computations   A: x10   B: x10   C: x10   D: x10   …\nThere were issues with some computations   A: x10   B: x10   C: x10   D: x10   …\n\ncollect_metrics(tuned_results) %&gt;%\n  count(.metric)\n\n# A tibble: 3 × 2\n  .metric     n\n  &lt;chr&gt;   &lt;int&gt;\n1 mae        25\n2 rmse       25\n3 rsq        25\n\nprint(metrics)\n\nfunction (data, ...) \n{\n    UseMethod(\"metrics\")\n}\n&lt;bytecode: 0x0000026b3d96e000&gt;\n&lt;environment: namespace:yardstick&gt;\n\ncollect_metrics(tuned_results) %&gt;%\n  filter(.metric == \"rmse\") %&gt;%\n  arrange(mean)\n\n# A tibble: 25 × 8\n    mtry min_n .metric .estimator  mean     n std_err .config              \n   &lt;int&gt; &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                \n 1    37    40 rmse    standard   0.521    10  0.0194 Preprocessor1_Model05\n 2    49    38 rmse    standard   0.522    10  0.0190 Preprocessor1_Model10\n 3    12    36 rmse    standard   0.522    10  0.0194 Preprocessor1_Model17\n 4    19    34 rmse    standard   0.523    10  0.0199 Preprocessor1_Model08\n 5    56    35 rmse    standard   0.523    10  0.0199 Preprocessor1_Model04\n 6    10    29 rmse    standard   0.525    10  0.0197 Preprocessor1_Model21\n 7     2    24 rmse    standard   0.525    10  0.0192 Preprocessor1_Model06\n 8    22    31 rmse    standard   0.526    10  0.0194 Preprocessor1_Model16\n 9    34    27 rmse    standard   0.526    10  0.0199 Preprocessor1_Model03\n10    14    30 rmse    standard   0.526    10  0.0196 Preprocessor1_Model19\n# ℹ 15 more rows\n\nshow_best(tuned_results, metric = \"mae\", n = 5)\n\n# A tibble: 5 × 8\n   mtry min_n .metric .estimator  mean     n std_err .config              \n  &lt;int&gt; &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                \n1     2    24 mae     standard   0.337    10  0.0146 Preprocessor1_Model06\n2    12    36 mae     standard   0.338    10  0.0152 Preprocessor1_Model17\n3    37    40 mae     standard   0.338    10  0.0148 Preprocessor1_Model05\n4    49    38 mae     standard   0.338    10  0.0149 Preprocessor1_Model10\n5    10    29 mae     standard   0.338    10  0.0155 Preprocessor1_Model21\n\n## Based off of the MAE metric, we can see that the best hyperparameter is 51 predictor samples, with the minimum of nodes for trends at 39. Based on the results the minimum nodes has results that range relatively close together, potentially showing that it handles the predictive data to the trained data better between 26-39 nodes.\n\nhp_best &lt;- select_best(\n  tuned_results,\n  metric = \"mae\")\n\n\n# 7. Finalize Your Model\n\nfinal_rf8_wf &lt;- finalize_workflow(\n  rf8wf_tune, \n  hp_best)"
  },
  {
    "objectID": "nm-hyperparameter-tuning.html#final-model-verification",
    "href": "nm-hyperparameter-tuning.html#final-model-verification",
    "title": "ESS330: Lab 8 - Hyperparameter Tuning QMD",
    "section": "Final Model Verification",
    "text": "Final Model Verification"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ESS 330: Lab 6 - Machine Learning in Hydrology",
    "section": "",
    "text": "library(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.4.3\n\n\nWarning: package 'ggplot2' was built under R version 4.4.3\n\n\nWarning: package 'tidyr' was built under R version 4.4.3\n\n\nWarning: package 'readr' was built under R version 4.4.3\n\n\nWarning: package 'purrr' was built under R version 4.4.3\n\n\nWarning: package 'dplyr' was built under R version 4.4.3\n\n\nWarning: package 'lubridate' was built under R version 4.4.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\nWarning: package 'tidymodels' was built under R version 4.4.3\n\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.3.0 ──\n✔ broom        1.0.8     ✔ rsample      1.2.1\n✔ dials        1.4.0     ✔ tune         1.3.0\n✔ infer        1.0.7     ✔ workflows    1.2.0\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.3.1     ✔ yardstick    1.3.2\n✔ recipes      1.1.1     \n\n\nWarning: package 'broom' was built under R version 4.4.3\n\n\nWarning: package 'dials' was built under R version 4.4.3\n\n\nWarning: package 'parsnip' was built under R version 4.4.3\n\n\nWarning: package 'recipes' was built under R version 4.4.3\n\n\nWarning: package 'tune' was built under R version 4.4.3\n\n\nWarning: package 'workflows' was built under R version 4.4.3\n\n\nWarning: package 'yardstick' was built under R version 4.4.3\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n\nlibrary(powerjoin)\n\nWarning: package 'powerjoin' was built under R version 4.4.3\n\nlibrary(glue)\n\nWarning: package 'glue' was built under R version 4.4.3\n\nlibrary(vip)\n\nWarning: package 'vip' was built under R version 4.4.3\n\n\n\nAttaching package: 'vip'\n\nThe following object is masked from 'package:utils':\n\n    vi\n\nlibrary(baguette)\n\nWarning: package 'baguette' was built under R version 4.4.3\n\nlibrary(broom)\n\n\nroot  &lt;- 'https://gdex.ucar.edu/dataset/camels/file'\n\n\n\nBasics:\n\ntypes &lt;- c(\"clim\", \"geol\", \"soil\", \"topo\", \"vege\", \"hydro\")\n\nremote_files  &lt;- glue('{root}/camels_{types}.txt')\n\nlocal_files   &lt;- glue('data/camels_{types}.txt')\n\nwalk2(remote_files, local_files, download.file, quiet = TRUE)\n\ncamels &lt;- map(local_files, read_delim, show_col_types = FALSE)\n\ncamels &lt;- power_full_join(camels ,by = 'gauge_id')\n\n\n\nQ in hydrology is represented as the amount of time it takes for a volume water to flow, discharge; while a zero frequency of discharge looks at the steady flow, that doesn’t change over multiple periods of time. Within this data set, the zero_q_fre will refer to the frequency of days where discharge is 0mm per day.\n\n\n\n\nggplot(data = camels, aes(x = gauge_lon, y = gauge_lat)) + \n  borders(\"state\", color = \"grey50\") +\n  geom_point(aes(color = q_mean)) +\n  scale_color_gradient(low = \"pink\", high = \"dodgerblue\") +\n  ggthemes::theme_map()\n\nWarning: Duplicated aesthetics after name standardisation: colour\n\n\n\n\n\n\n\n\n\n\n\n\n\nObjectives: 1. Make 2 maps of the sites, coloring the points by the aridty and p_mean column 2. Add clear labels, titles, and a color scale that makes sense for each parameter. 3. Ensure these render as a single image with your choice of facet_*, patchwork, or ggpubr\n\nModel Preparation\n\n\ncamels |&gt; \n  select(aridity, p_mean, q_mean) |&gt; \n  drop_na() |&gt; \n  cor()\n\n           aridity     p_mean     q_mean\naridity  1.0000000 -0.7550090 -0.5817771\np_mean  -0.7550090  1.0000000  0.8865757\nq_mean  -0.5817771  0.8865757  1.0000000\n\n\n\nVisual EDA:\n\n\n# Create a scatter plot of aridity vs rainfall\nggplot(camels, aes(x = aridity, y = p_mean)) +\n  # Add points colored by mean flow\n  geom_point(aes(color = q_mean)) +\n  # Add a linear regression line\n  geom_smooth(method = \"lm\", color = \"red\", linetype = 2) +\n  # Apply the viridis color scale\n  scale_color_viridis_c() +\n  # Add a title, axis labels, and theme (w/ legend on the bottom)\n  theme_linedraw() + \n  theme(legend.position = \"bottom\") + \n  labs(title = \"Aridity vs Rainfall vs Runnoff\", \n       x = \"Aridity\", \n       y = \"Rainfall\",\n       color = \"Mean Flow\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nTesting a Transformation:\n\nggplot(camels, aes(x = aridity, y = p_mean)) +\n  geom_point(aes(color = q_mean)) +\n  geom_smooth(method = \"lm\") +\n  scale_color_viridis_c() +\n  # Apply log transformations to the x and y axes\n  scale_x_log10() + \n  scale_y_log10() +\n  theme_linedraw() +\n  theme(legend.position = \"bottom\") + \n  labs(title = \"Aridity vs Rainfall vs Runnoff\", \n       x = \"Aridity\", \n       y = \"Rainfall\",\n       color = \"Mean Flow\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nNew and Improved:\n\nggplot(camels, aes(x = aridity, y = p_mean)) +\n  geom_point(aes(color = q_mean)) +\n  geom_smooth(method = \"lm\") +\n  # Apply a log transformation to the color scale\n  scale_color_viridis_c(trans = \"log\") +\n  scale_x_log10() + \n  scale_y_log10() +\n  theme_linedraw() +\n  theme(legend.position = \"bottom\",\n        # Expand the legend width ...\n        legend.key.width = unit(2.5, \"cm\"),\n        legend.key.height = unit(.5, \"cm\")) + \n  labs(title = \"Aridity vs Rainfall vs Runnoff\", \n       x = \"Aridity\", \n       y = \"Rainfall\",\n       color = \"Mean Flow\") \n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nModel Building:\n\n#Splitting the data into training and testing\n\nset.seed(123)\n\ncamels &lt;- camels |&gt;\n  mutate(logQmean = log(q_mean))\n\ncamels_split &lt;- initial_split(camels, prop = 0.80)\n\ncamels_train &lt;- training(camels_split)\n\ncamels_test &lt;- testing(camels_split)\n\ncamels_cv &lt;- vfold_cv(camels_train, v = 10)\n\n\n#Building the recipe\n\nrec &lt;- recipe(logQmean ~ aridity + p_mean, data = camels_train) %&gt;%\n  step_log(all_predictors()) %&gt;%\n  step_interact(terms = ~ aridity:p_mean) |&gt;\n  step_naomit(all_predictors(), all_outcomes())\n\n\n#Calling the data to a linear model\n\nbaked_data &lt;- prep(rec, camels_train) |&gt;\n  bake(new_data = NULL)\n\nlm_base &lt;- lm(logQmean ~ aridity * p_mean, data = baked_data)\n\nsummary(lm_base)\n\n\nCall:\nlm(formula = logQmean ~ aridity * p_mean, data = baked_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.91162 -0.21601 -0.00716  0.21230  2.85706 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    -1.77586    0.16365 -10.852  &lt; 2e-16 ***\naridity        -0.88397    0.16145  -5.475 6.75e-08 ***\np_mean          1.48438    0.15511   9.570  &lt; 2e-16 ***\naridity:p_mean  0.10484    0.07198   1.457    0.146    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5696 on 531 degrees of freedom\nMultiple R-squared:  0.7697,    Adjusted R-squared:  0.7684 \nF-statistic: 591.6 on 3 and 531 DF,  p-value: &lt; 2.2e-16\n\n\n\n# Sanity CHECK!\n\nsummary(lm(logQmean ~ aridity + p_mean + aridity_x_p_mean, data = baked_data))\n\n\nCall:\nlm(formula = logQmean ~ aridity + p_mean + aridity_x_p_mean, \n    data = baked_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.91162 -0.21601 -0.00716  0.21230  2.85706 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      -1.77586    0.16365 -10.852  &lt; 2e-16 ***\naridity          -0.88397    0.16145  -5.475 6.75e-08 ***\np_mean            1.48438    0.15511   9.570  &lt; 2e-16 ***\naridity_x_p_mean  0.10484    0.07198   1.457    0.146    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5696 on 531 degrees of freedom\nMultiple R-squared:  0.7697,    Adjusted R-squared:  0.7684 \nF-statistic: 591.6 on 3 and 531 DF,  p-value: &lt; 2.2e-16\n\n\nPASSED! BUT - now we test to see if our trained model and need to validate the tested data!\n\n# It's times to prep, bake, and predict:\n\n\ntest_data &lt;- bake(prep(rec), new_data = camels_test)\n\ntest_data$lm_pred &lt;- predict(lm_base, newdata = test_data)\n\nModel Evaluation: Statistical and Visual\n\nmetrics(test_data, truth = logQmean, estimate = lm_pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.583\n2 rsq     standard       0.742\n3 mae     standard       0.390\n\n\n\nggplot(test_data, aes(x = logQmean, y = lm_pred, color = aridity)) +\n  scale_color_gradient2(low = \"brown\", mid = \"orange\", high = \"darkgreen\") +\n  geom_point() +\n  geom_abline(linetype = 2) +\n  theme_linedraw() +\n  labs(title = \"Linear Model: Observed vs. Predicted\",\n       x = \"Observed Log Mean Flow\",\n       y = \"Predicted Log Mean Flow\",\n       color = \"Aridity\")\n\n\n\n\n\n\n\n\n\n\n\n# Defining a model:\nlm_model &lt;- linear_reg() %&gt;%\n  set_engine('lm') %&gt;%\n  set_mode(\"regression\")\n\n#Instantiate the workflow:\nlm_wf &lt;- workflow() %&gt;%\n  add_recipe(rec) %&gt;%\n  add_model(lm_model) %&gt;%\n  fit(data = camels_train)\n\nsummary(extract_fit_engine(lm_wf))$coefficients\n\n                   Estimate Std. Error    t value     Pr(&gt;|t|)\n(Intercept)      -1.7758557 0.16364755 -10.851710 6.463654e-25\naridity          -0.8839738 0.16144589  -5.475357 6.745512e-08\np_mean            1.4843771 0.15511117   9.569762 4.022500e-20\naridity_x_p_mean  0.1048449 0.07198145   1.456555 1.458304e-01\n\n\nMaking Predictions\n\n#NOW WE USE AUGMENT!\n\nlm_data &lt;- augment(lm_wf, new_data = camels_test)\n\ndim(lm_data)\n\n[1] 135  61\n\n\nModel Evaluation\n\nmetrics(lm_data, truth = logQmean, estimate = .pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.583\n2 rsq     standard       0.742\n3 mae     standard       0.390\n\n\n\nggplot(lm_data, aes(x = logQmean, y = .pred, color = aridity)) +\n  scale_color_viridis_c() +\n  geom_point() +\n  geom_abline() +\n  theme_linedraw()\n\n\n\n\n\n\n\n\nSWITCHING IT UP!\n\n# Using the Random Forest Model!\nlibrary(baguette)\n\nrf_model &lt;- rand_forest() %&gt;%\n  set_engine(\"ranger\", importance = \"impurity\") %&gt;%\n  set_mode(\"regression\")\n\nrf_wf &lt;- workflow() %&gt;%\n  add_recipe(rec) %&gt;%\n  add_model(rf_model) %&gt;%\n  fit(data = camels_train)\n\n\n# Making Predictions:\n\nrf_data &lt;- augment(rf_wf, new_data = camels_test)\ndim(rf_data)\n\n[1] 135  60\n\n\n\n# Model Evaluating:\n\nmetrics(rf_data, truth = logQmean, estimate = .pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.596\n2 rsq     standard       0.733\n3 mae     standard       0.370\n\n\n\n#Plotting:\nggplot(rf_data, aes(x = logQmean, y = .pred, color = aridity)) +\n  scale_color_viridis_c() +\n  geom_point() +\n  geom_abline() +\n  theme_linedraw()\n\n\n\n\n\n\n\n\nWORKFLOW SET APPROACH!\n\nwf &lt;- workflow_set(list(rec), list(lm_model, rf_model)) %&gt;%\n  workflow_map('fit_resamples', resamples = camels_cv)\n\nWarning: package 'ranger' was built under R version 4.4.3\n\nautoplot(wf)\n\n\n\n\n\n\n\n\n\nrank_results(wf, rank_metric = \"rsq\", select_best = TRUE)\n\n# A tibble: 4 × 9\n  wflow_id          .config .metric  mean std_err     n preprocessor model  rank\n  &lt;chr&gt;             &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;        &lt;chr&gt; &lt;int&gt;\n1 recipe_rand_fore… Prepro… rmse    0.565  0.0243    10 recipe       rand…     1\n2 recipe_rand_fore… Prepro… rsq     0.770  0.0255    10 recipe       rand…     1\n3 recipe_linear_reg Prepro… rmse    0.569  0.0260    10 recipe       line…     2\n4 recipe_linear_reg Prepro… rsq     0.770  0.0223    10 recipe       line…     2\n\n\n\n\n\n\n\n# XG Boost Model\n\nb_model &lt;- boost_tree() %&gt;%\n  set_engine(\"xgboost\") %&gt;%\n  set_mode(\"regression\")\n\nb_wf &lt;- workflow() %&gt;%\n  add_recipe(rec) %&gt;%\n  add_model(b_model) %&gt;%\n  fit(data = camels_train)\n\n\nb_data &lt;- augment(b_wf, new_data = camels_test)\ndim(b_data)\n\n[1] 135  60\n\n\n\nmetrics(b_data, truth = logQmean, estimate = .pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.631\n2 rsq     standard       0.702\n3 mae     standard       0.397\n\n\n\n# Checking metrics:\nggplot(b_data, aes(x = logQmean, y = .pred, colour = aridity)) +\n  scale_color_viridis_c() +\n  geom_point() +\n  geom_abline() +\n  theme_linedraw()\n\n\n\n\n\n\n\n\n\n# Neural Network time:\n\nnn_model &lt;- mlp(hidden_units = 5, penalty = 0.01) %&gt;%\n  set_engine(\"nnet\") %&gt;%\n  set_mode(\"regression\")\n\nnn_wf &lt;- workflow() %&gt;%\n  add_recipe(rec) %&gt;%\n  add_model(nn_model) %&gt;%\n  fit(data = camels_train)\n\nnn_data &lt;- augment(nn_wf, new_data = camels_test)\ndim(nn_data)\n\n[1] 135  61\n\n\n\nmetrics(nn_data, truth = logQmean, estimate = .pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.553\n2 rsq     standard       0.767\n3 mae     standard       0.350\n\n\n\nggplot(nn_data, aes(x = logQmean, y = .pred, colour = aridity)) +\n  scale_color_viridis_c() +\n  geom_point() +\n  geom_abline() +\n  theme_linedraw()\n\n\n\n\n\n\n\n\nCombining all (linear regression, random Forest, XG Boost, and Neural Network Models)\n\nwf &lt;- workflow_set(list(rec), list(lm_model, rf_model, b_model, nn_model)) %&gt;%\n  workflow_map('fit_resamples', resamples = camels_cv)\n\nWarning: package 'xgboost' was built under R version 4.4.3\n\nautoplot(wf)\n\n\n\n\n\n\n\n\n\nrank_results(wf, rank_metric = \"rsq\", select_best = TRUE)\n\n# A tibble: 8 × 9\n  wflow_id          .config .metric  mean std_err     n preprocessor model  rank\n  &lt;chr&gt;             &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;        &lt;chr&gt; &lt;int&gt;\n1 recipe_mlp        Prepro… rmse    0.523  0.0307    10 recipe       mlp       1\n2 recipe_mlp        Prepro… rsq     0.801  0.0257    10 recipe       mlp       1\n3 recipe_rand_fore… Prepro… rmse    0.562  0.0258    10 recipe       rand…     2\n4 recipe_rand_fore… Prepro… rsq     0.771  0.0268    10 recipe       rand…     2\n5 recipe_linear_reg Prepro… rmse    0.569  0.0260    10 recipe       line…     3\n6 recipe_linear_reg Prepro… rsq     0.770  0.0223    10 recipe       line…     3\n7 recipe_boost_tree Prepro… rmse    0.600  0.0289    10 recipe       boos…     4\n8 recipe_boost_tree Prepro… rsq     0.745  0.0268    10 recipe       boos…     4\n\n\nFrom these tests, we can understand that the neural network and mlp model are performing better for rmsq and rsq in the linear model than the linear and random forests models.\nWe will move forward with the neural network model to understand this relationship between Observed Log Mean Flow, Predicted Log Mean Flow, and Aridity.\n\n\n\nstreamflow predictions\n\n# Data Splitting\n\nset.seed(123)\n\ncamels &lt;- camels |&gt;\n  mutate(logQmean = log(q_mean))\n\ncamels_split &lt;- initial_split(camels, prop = 0.75)\n\ncamels_train &lt;- training(camels_split)\n\ncamels_test &lt;- testing(camels_split)\n\ncamels_cv &lt;- vfold_cv(camels_train, v = 10)\n\n\n# Recipe\n\nrec &lt;- recipe(logQmean ~ p_mean + max_water_content, data = camels_train) %&gt;%\n  step_log(all_predictors()) %&gt;%\n  step_interact(terms = ~ p_mean:max_water_content) |&gt;\n  step_naomit(all_predictors(), all_outcomes())\n\nI chose to look at the relationship the precipitation mean has with the maximum water content of soil profiles. This will help us understand if the discharge mean of streamflow as it is related to the maximum water content that can be retained before becoming discharge. Seen below:\n\nbaked_data &lt;- prep(rec, camels_train) |&gt;\n  bake(new_data = NULL)\n\nlm_base &lt;- lm(logQmean ~ p_mean * max_water_content, data = baked_data)\n\nsummary(lm_base)\n\n\nCall:\nlm(formula = logQmean ~ p_mean * max_water_content, data = baked_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.70495 -0.31108  0.04349  0.28573  2.06245 \n\nCoefficients:\n                         Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)               -3.2241     0.1451 -22.214  &lt; 2e-16 ***\np_mean                     2.6732     0.1341  19.931  &lt; 2e-16 ***\nmax_water_content         -0.5949     0.1352  -4.400 1.33e-05 ***\np_mean:max_water_content   0.3081     0.1399   2.203   0.0281 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5775 on 498 degrees of freedom\nMultiple R-squared:  0.7668,    Adjusted R-squared:  0.7654 \nF-statistic: 545.9 on 3 and 498 DF,  p-value: &lt; 2.2e-16\n\n\n\ntest_data &lt;- bake(prep(rec), new_data = camels_test)\n\ntest_data$lm_pred &lt;- predict(lm_base, newdata = test_data)\n\nmetrics(test_data, truth = logQmean, estimate = lm_pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.572\n2 rsq     standard       0.746\n3 mae     standard       0.427\n\n\n\n# Defining Random Forest Model\n\nlibrary(baguette)\n\nrf_model &lt;- rand_forest() %&gt;%\n  set_engine(\"ranger\", importance = \"impurity\") %&gt;%\n  set_mode(\"regression\")\n\n\n#Creating and Adding it to the workflow set\nrf_wf &lt;- workflow() %&gt;%\n  add_recipe(rec) %&gt;%\n  add_model(rf_model) %&gt;%\n  fit(data = camels_train)\n\n\nrf_data &lt;- augment(rf_wf, new_data = camels_test)\ndim(rf_data)\n\n[1] 168  60\n\n\n\nmetrics(rf_data, truth = logQmean, estimate = .pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.600\n2 rsq     standard       0.720\n3 mae     standard       0.399\n\n\n\nggplot(rf_data, aes(x = logQmean, y = .pred, color = max_water_content)) +\n  scale_color_viridis_c() +\n  geom_point() +\n  geom_abline() +\n  theme_linedraw()\n\n\n\n\n\n\n\n\n\n# Defining a Linear Regression Model\nlm_model &lt;- linear_reg() %&gt;%\n  set_engine('lm') %&gt;%\n  set_mode(\"regression\")\n\n#Instantiate the workflow:\nlm_wf &lt;- workflow() %&gt;%\n  add_recipe(rec) %&gt;%\n  add_model(lm_model) %&gt;%\n  fit(data = camels_train)\n\nsummary(extract_fit_engine(lm_wf))$coefficients\n\n                             Estimate Std. Error    t value     Pr(&gt;|t|)\n(Intercept)                -3.2240978  0.1451356 -22.214387 1.734810e-76\np_mean                      2.6732285  0.1341254  19.930812 2.022897e-65\nmax_water_content          -0.5949414  0.1352244  -4.399662 1.326996e-05\np_mean_x_max_water_content  0.3080732  0.1398610   2.202709 2.807261e-02\n\n\n\nlm_data &lt;- augment(lm_wf, new_data = camels_test)\n\ndim(lm_data)\n\n[1] 168  61\n\n\n\nmetrics(lm_data, truth = logQmean, estimate = .pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.572\n2 rsq     standard       0.746\n3 mae     standard       0.427\n\nggplot(lm_data, aes(x = logQmean, y = .pred, color = max_water_content)) +\n  scale_color_viridis_c() +\n  geom_point() +\n  geom_abline() +\n  theme_linedraw()\n\n\n\n\n\n\n\n\n\n# Defining a XG Boost Model\n\nb_model &lt;- boost_tree() %&gt;%\n  set_engine('xgboost') %&gt;%\n  set_mode(\"regression\")\n\nb_wf &lt;- workflow() %&gt;%\n  add_recipe(rec) %&gt;%\n  add_model(b_model) %&gt;%\n  fit(data = camels_train)\n\n\nb_data &lt;- augment(b_wf, new_data = camels_test)\ndim(b_data)\n\n[1] 168  60\n\n\n\nmetrics(b_data, truth = logQmean, estimate = .pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.671\n2 rsq     standard       0.662\n3 mae     standard       0.425\n\n\n\n# Checking metrics:\nggplot(b_data, aes(x = logQmean, y = .pred, colour = aridity)) +\n  scale_color_viridis_c() +\n  geom_point() +\n  geom_abline() +\n  theme_linedraw()\n\n\n\n\n\n\n\n\nworkflow set and Evaluating\n\nwf_obj &lt;- workflow_set(list(rec), list(rf_model, lm_model, b_model)) %&gt;%\n  workflow_map('fit_resamples', resamples = camels_cv)\n\nautoplot(wf_obj)\n\n\n\n\n\n\n\n\n\nrank_results(wf_obj, rank_metric = \"rsq\", select_best = TRUE)\n\n# A tibble: 6 × 9\n  wflow_id          .config .metric  mean std_err     n preprocessor model  rank\n  &lt;chr&gt;             &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;        &lt;chr&gt; &lt;int&gt;\n1 recipe_rand_fore… Prepro… rmse    0.566  0.0239    10 recipe       rand…     1\n2 recipe_rand_fore… Prepro… rsq     0.779  0.0191    10 recipe       rand…     1\n3 recipe_linear_reg Prepro… rmse    0.578  0.0248    10 recipe       line…     2\n4 recipe_linear_reg Prepro… rsq     0.766  0.0194    10 recipe       line…     2\n5 recipe_boost_tree Prepro… rmse    0.593  0.0241    10 recipe       boos…     3\n6 recipe_boost_tree Prepro… rsq     0.758  0.0198    10 recipe       boos…     3\n\n\nFor understanding the relationship max water content of soils and precipitation means as they affect discharge mean rates, we should use the random forest model to continue this testing and training of the camels data. Based on the ranking and autoplot the random forest model performs better for understanding the predicted mean streamflow.\n\n# Extract and Evaluate\n\nrf_fit = workflow() |&gt;\n  add_recipe(rec) |&gt;\n  add_model(rf_model) |&gt;\n  fit(camels_train)\n\na = augment(rf_fit, new_data = camels_train)\n\nggplot(a, aes(x = .pred, y = logQmean)) +\n  geom_point()\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\nvip::vip(rf_fit)\n\n\n\n\n\n\n\n\n\nggplot(a, aes(x = logQmean, y = .pred, color = max_water_content)) +\n  scale_color_gradient2(low = \"red\", mid = \"yellow\", high = \"blue2\") +\n  geom_point() +\n  geom_abline(linetype = 2) +\n  theme_linedraw() +\n  labs(title = \"Random Forest Model: Observed vs. Predicted Mean Streamflow\",\n       x = \"Observed Log Mean Flow\",\n       y = \"Predicted Log Mean Flow\",\n       color = \"Max Water Content\")\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nBased on the graph and evaluated workflow for the predicted mean streamflow as it is related to the observed mean streamflow, we can understand that the max water content of the soil profiles and mean precipitation do have a significant influence on streamflow that is seen in the predicted and observed values. Random forest helped us by being able to handle the large data set, while reducing the overfitting of a decision tree to increase it’s accuracy. We can see this in the graph above and the precipiation mean had more importance in relation to mean streamflow discharge. In the beginning of this modelling, we had an R-squared value of 0.7645, understanding that this data was not a successful fit to begin with, responds to how the importance of max water content differs from precipitation mean."
  },
  {
    "objectID": "index.html#question-1-your-turn",
    "href": "index.html#question-1-your-turn",
    "title": "ESS 330: Lab 6 - Machine Learning in Hydrology",
    "section": "",
    "text": "Basics:\n\ntypes &lt;- c(\"clim\", \"geol\", \"soil\", \"topo\", \"vege\", \"hydro\")\n\nremote_files  &lt;- glue('{root}/camels_{types}.txt')\n\nlocal_files   &lt;- glue('data/camels_{types}.txt')\n\nwalk2(remote_files, local_files, download.file, quiet = TRUE)\n\ncamels &lt;- map(local_files, read_delim, show_col_types = FALSE)\n\ncamels &lt;- power_full_join(camels ,by = 'gauge_id')\n\n\n\nQ in hydrology is represented as the amount of time it takes for a volume water to flow, discharge; while a zero frequency of discharge looks at the steady flow, that doesn’t change over multiple periods of time. Within this data set, the zero_q_fre will refer to the frequency of days where discharge is 0mm per day.\n\n\n\n\nggplot(data = camels, aes(x = gauge_lon, y = gauge_lat)) + \n  borders(\"state\", color = \"grey50\") +\n  geom_point(aes(color = q_mean)) +\n  scale_color_gradient(low = \"pink\", high = \"dodgerblue\") +\n  ggthemes::theme_map()\n\nWarning: Duplicated aesthetics after name standardisation: colour"
  },
  {
    "objectID": "index.html#question-2-your-turn",
    "href": "index.html#question-2-your-turn",
    "title": "ESS 330: Lab 6 - Machine Learning in Hydrology",
    "section": "",
    "text": "Objectives: 1. Make 2 maps of the sites, coloring the points by the aridty and p_mean column 2. Add clear labels, titles, and a color scale that makes sense for each parameter. 3. Ensure these render as a single image with your choice of facet_*, patchwork, or ggpubr\n\nModel Preparation\n\n\ncamels |&gt; \n  select(aridity, p_mean, q_mean) |&gt; \n  drop_na() |&gt; \n  cor()\n\n           aridity     p_mean     q_mean\naridity  1.0000000 -0.7550090 -0.5817771\np_mean  -0.7550090  1.0000000  0.8865757\nq_mean  -0.5817771  0.8865757  1.0000000\n\n\n\nVisual EDA:\n\n\n# Create a scatter plot of aridity vs rainfall\nggplot(camels, aes(x = aridity, y = p_mean)) +\n  # Add points colored by mean flow\n  geom_point(aes(color = q_mean)) +\n  # Add a linear regression line\n  geom_smooth(method = \"lm\", color = \"red\", linetype = 2) +\n  # Apply the viridis color scale\n  scale_color_viridis_c() +\n  # Add a title, axis labels, and theme (w/ legend on the bottom)\n  theme_linedraw() + \n  theme(legend.position = \"bottom\") + \n  labs(title = \"Aridity vs Rainfall vs Runnoff\", \n       x = \"Aridity\", \n       y = \"Rainfall\",\n       color = \"Mean Flow\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nTesting a Transformation:\n\nggplot(camels, aes(x = aridity, y = p_mean)) +\n  geom_point(aes(color = q_mean)) +\n  geom_smooth(method = \"lm\") +\n  scale_color_viridis_c() +\n  # Apply log transformations to the x and y axes\n  scale_x_log10() + \n  scale_y_log10() +\n  theme_linedraw() +\n  theme(legend.position = \"bottom\") + \n  labs(title = \"Aridity vs Rainfall vs Runnoff\", \n       x = \"Aridity\", \n       y = \"Rainfall\",\n       color = \"Mean Flow\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nNew and Improved:\n\nggplot(camels, aes(x = aridity, y = p_mean)) +\n  geom_point(aes(color = q_mean)) +\n  geom_smooth(method = \"lm\") +\n  # Apply a log transformation to the color scale\n  scale_color_viridis_c(trans = \"log\") +\n  scale_x_log10() + \n  scale_y_log10() +\n  theme_linedraw() +\n  theme(legend.position = \"bottom\",\n        # Expand the legend width ...\n        legend.key.width = unit(2.5, \"cm\"),\n        legend.key.height = unit(.5, \"cm\")) + \n  labs(title = \"Aridity vs Rainfall vs Runnoff\", \n       x = \"Aridity\", \n       y = \"Rainfall\",\n       color = \"Mean Flow\") \n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nModel Building:\n\n#Splitting the data into training and testing\n\nset.seed(123)\n\ncamels &lt;- camels |&gt;\n  mutate(logQmean = log(q_mean))\n\ncamels_split &lt;- initial_split(camels, prop = 0.80)\n\ncamels_train &lt;- training(camels_split)\n\ncamels_test &lt;- testing(camels_split)\n\ncamels_cv &lt;- vfold_cv(camels_train, v = 10)\n\n\n#Building the recipe\n\nrec &lt;- recipe(logQmean ~ aridity + p_mean, data = camels_train) %&gt;%\n  step_log(all_predictors()) %&gt;%\n  step_interact(terms = ~ aridity:p_mean) |&gt;\n  step_naomit(all_predictors(), all_outcomes())\n\n\n#Calling the data to a linear model\n\nbaked_data &lt;- prep(rec, camels_train) |&gt;\n  bake(new_data = NULL)\n\nlm_base &lt;- lm(logQmean ~ aridity * p_mean, data = baked_data)\n\nsummary(lm_base)\n\n\nCall:\nlm(formula = logQmean ~ aridity * p_mean, data = baked_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.91162 -0.21601 -0.00716  0.21230  2.85706 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    -1.77586    0.16365 -10.852  &lt; 2e-16 ***\naridity        -0.88397    0.16145  -5.475 6.75e-08 ***\np_mean          1.48438    0.15511   9.570  &lt; 2e-16 ***\naridity:p_mean  0.10484    0.07198   1.457    0.146    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5696 on 531 degrees of freedom\nMultiple R-squared:  0.7697,    Adjusted R-squared:  0.7684 \nF-statistic: 591.6 on 3 and 531 DF,  p-value: &lt; 2.2e-16\n\n\n\n# Sanity CHECK!\n\nsummary(lm(logQmean ~ aridity + p_mean + aridity_x_p_mean, data = baked_data))\n\n\nCall:\nlm(formula = logQmean ~ aridity + p_mean + aridity_x_p_mean, \n    data = baked_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.91162 -0.21601 -0.00716  0.21230  2.85706 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      -1.77586    0.16365 -10.852  &lt; 2e-16 ***\naridity          -0.88397    0.16145  -5.475 6.75e-08 ***\np_mean            1.48438    0.15511   9.570  &lt; 2e-16 ***\naridity_x_p_mean  0.10484    0.07198   1.457    0.146    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5696 on 531 degrees of freedom\nMultiple R-squared:  0.7697,    Adjusted R-squared:  0.7684 \nF-statistic: 591.6 on 3 and 531 DF,  p-value: &lt; 2.2e-16\n\n\nPASSED! BUT - now we test to see if our trained model and need to validate the tested data!\n\n# It's times to prep, bake, and predict:\n\n\ntest_data &lt;- bake(prep(rec), new_data = camels_test)\n\ntest_data$lm_pred &lt;- predict(lm_base, newdata = test_data)\n\nModel Evaluation: Statistical and Visual\n\nmetrics(test_data, truth = logQmean, estimate = lm_pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.583\n2 rsq     standard       0.742\n3 mae     standard       0.390\n\n\n\nggplot(test_data, aes(x = logQmean, y = lm_pred, color = aridity)) +\n  scale_color_gradient2(low = \"brown\", mid = \"orange\", high = \"darkgreen\") +\n  geom_point() +\n  geom_abline(linetype = 2) +\n  theme_linedraw() +\n  labs(title = \"Linear Model: Observed vs. Predicted\",\n       x = \"Observed Log Mean Flow\",\n       y = \"Predicted Log Mean Flow\",\n       color = \"Aridity\")\n\n\n\n\n\n\n\n\n\n\n\n# Defining a model:\nlm_model &lt;- linear_reg() %&gt;%\n  set_engine('lm') %&gt;%\n  set_mode(\"regression\")\n\n#Instantiate the workflow:\nlm_wf &lt;- workflow() %&gt;%\n  add_recipe(rec) %&gt;%\n  add_model(lm_model) %&gt;%\n  fit(data = camels_train)\n\nsummary(extract_fit_engine(lm_wf))$coefficients\n\n                   Estimate Std. Error    t value     Pr(&gt;|t|)\n(Intercept)      -1.7758557 0.16364755 -10.851710 6.463654e-25\naridity          -0.8839738 0.16144589  -5.475357 6.745512e-08\np_mean            1.4843771 0.15511117   9.569762 4.022500e-20\naridity_x_p_mean  0.1048449 0.07198145   1.456555 1.458304e-01\n\n\nMaking Predictions\n\n#NOW WE USE AUGMENT!\n\nlm_data &lt;- augment(lm_wf, new_data = camels_test)\n\ndim(lm_data)\n\n[1] 135  61\n\n\nModel Evaluation\n\nmetrics(lm_data, truth = logQmean, estimate = .pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.583\n2 rsq     standard       0.742\n3 mae     standard       0.390\n\n\n\nggplot(lm_data, aes(x = logQmean, y = .pred, color = aridity)) +\n  scale_color_viridis_c() +\n  geom_point() +\n  geom_abline() +\n  theme_linedraw()\n\n\n\n\n\n\n\n\nSWITCHING IT UP!\n\n# Using the Random Forest Model!\nlibrary(baguette)\n\nrf_model &lt;- rand_forest() %&gt;%\n  set_engine(\"ranger\", importance = \"impurity\") %&gt;%\n  set_mode(\"regression\")\n\nrf_wf &lt;- workflow() %&gt;%\n  add_recipe(rec) %&gt;%\n  add_model(rf_model) %&gt;%\n  fit(data = camels_train)\n\n\n# Making Predictions:\n\nrf_data &lt;- augment(rf_wf, new_data = camels_test)\ndim(rf_data)\n\n[1] 135  60\n\n\n\n# Model Evaluating:\n\nmetrics(rf_data, truth = logQmean, estimate = .pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.596\n2 rsq     standard       0.733\n3 mae     standard       0.370\n\n\n\n#Plotting:\nggplot(rf_data, aes(x = logQmean, y = .pred, color = aridity)) +\n  scale_color_viridis_c() +\n  geom_point() +\n  geom_abline() +\n  theme_linedraw()\n\n\n\n\n\n\n\n\nWORKFLOW SET APPROACH!\n\nwf &lt;- workflow_set(list(rec), list(lm_model, rf_model)) %&gt;%\n  workflow_map('fit_resamples', resamples = camels_cv)\n\nWarning: package 'ranger' was built under R version 4.4.3\n\nautoplot(wf)\n\n\n\n\n\n\n\n\n\nrank_results(wf, rank_metric = \"rsq\", select_best = TRUE)\n\n# A tibble: 4 × 9\n  wflow_id          .config .metric  mean std_err     n preprocessor model  rank\n  &lt;chr&gt;             &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;        &lt;chr&gt; &lt;int&gt;\n1 recipe_rand_fore… Prepro… rmse    0.565  0.0243    10 recipe       rand…     1\n2 recipe_rand_fore… Prepro… rsq     0.770  0.0255    10 recipe       rand…     1\n3 recipe_linear_reg Prepro… rmse    0.569  0.0260    10 recipe       line…     2\n4 recipe_linear_reg Prepro… rsq     0.770  0.0223    10 recipe       line…     2"
  },
  {
    "objectID": "index.html#question-3-building-xgboost-and-neural-networks",
    "href": "index.html#question-3-building-xgboost-and-neural-networks",
    "title": "ESS 330: Lab 6 - Machine Learning in Hydrology",
    "section": "",
    "text": "# XG Boost Model\n\nb_model &lt;- boost_tree() %&gt;%\n  set_engine(\"xgboost\") %&gt;%\n  set_mode(\"regression\")\n\nb_wf &lt;- workflow() %&gt;%\n  add_recipe(rec) %&gt;%\n  add_model(b_model) %&gt;%\n  fit(data = camels_train)\n\n\nb_data &lt;- augment(b_wf, new_data = camels_test)\ndim(b_data)\n\n[1] 135  60\n\n\n\nmetrics(b_data, truth = logQmean, estimate = .pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.631\n2 rsq     standard       0.702\n3 mae     standard       0.397\n\n\n\n# Checking metrics:\nggplot(b_data, aes(x = logQmean, y = .pred, colour = aridity)) +\n  scale_color_viridis_c() +\n  geom_point() +\n  geom_abline() +\n  theme_linedraw()\n\n\n\n\n\n\n\n\n\n# Neural Network time:\n\nnn_model &lt;- mlp(hidden_units = 5, penalty = 0.01) %&gt;%\n  set_engine(\"nnet\") %&gt;%\n  set_mode(\"regression\")\n\nnn_wf &lt;- workflow() %&gt;%\n  add_recipe(rec) %&gt;%\n  add_model(nn_model) %&gt;%\n  fit(data = camels_train)\n\nnn_data &lt;- augment(nn_wf, new_data = camels_test)\ndim(nn_data)\n\n[1] 135  61\n\n\n\nmetrics(nn_data, truth = logQmean, estimate = .pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.553\n2 rsq     standard       0.767\n3 mae     standard       0.350\n\n\n\nggplot(nn_data, aes(x = logQmean, y = .pred, colour = aridity)) +\n  scale_color_viridis_c() +\n  geom_point() +\n  geom_abline() +\n  theme_linedraw()\n\n\n\n\n\n\n\n\nCombining all (linear regression, random Forest, XG Boost, and Neural Network Models)\n\nwf &lt;- workflow_set(list(rec), list(lm_model, rf_model, b_model, nn_model)) %&gt;%\n  workflow_map('fit_resamples', resamples = camels_cv)\n\nWarning: package 'xgboost' was built under R version 4.4.3\n\nautoplot(wf)\n\n\n\n\n\n\n\n\n\nrank_results(wf, rank_metric = \"rsq\", select_best = TRUE)\n\n# A tibble: 8 × 9\n  wflow_id          .config .metric  mean std_err     n preprocessor model  rank\n  &lt;chr&gt;             &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;        &lt;chr&gt; &lt;int&gt;\n1 recipe_mlp        Prepro… rmse    0.523  0.0307    10 recipe       mlp       1\n2 recipe_mlp        Prepro… rsq     0.801  0.0257    10 recipe       mlp       1\n3 recipe_rand_fore… Prepro… rmse    0.562  0.0258    10 recipe       rand…     2\n4 recipe_rand_fore… Prepro… rsq     0.771  0.0268    10 recipe       rand…     2\n5 recipe_linear_reg Prepro… rmse    0.569  0.0260    10 recipe       line…     3\n6 recipe_linear_reg Prepro… rsq     0.770  0.0223    10 recipe       line…     3\n7 recipe_boost_tree Prepro… rmse    0.600  0.0289    10 recipe       boos…     4\n8 recipe_boost_tree Prepro… rsq     0.745  0.0268    10 recipe       boos…     4\n\n\nFrom these tests, we can understand that the neural network and mlp model are performing better for rmsq and rsq in the linear model than the linear and random forests models.\nWe will move forward with the neural network model to understand this relationship between Observed Log Mean Flow, Predicted Log Mean Flow, and Aridity."
  },
  {
    "objectID": "index.html#building-my-own-testtrain-model",
    "href": "index.html#building-my-own-testtrain-model",
    "title": "ESS 330: Lab 6 - Machine Learning in Hydrology",
    "section": "",
    "text": "streamflow predictions\n\n# Data Splitting\n\nset.seed(123)\n\ncamels &lt;- camels |&gt;\n  mutate(logQmean = log(q_mean))\n\ncamels_split &lt;- initial_split(camels, prop = 0.75)\n\ncamels_train &lt;- training(camels_split)\n\ncamels_test &lt;- testing(camels_split)\n\ncamels_cv &lt;- vfold_cv(camels_train, v = 10)\n\n\n# Recipe\n\nrec &lt;- recipe(logQmean ~ p_mean + max_water_content, data = camels_train) %&gt;%\n  step_log(all_predictors()) %&gt;%\n  step_interact(terms = ~ p_mean:max_water_content) |&gt;\n  step_naomit(all_predictors(), all_outcomes())\n\nI chose to look at the relationship the precipitation mean has with the maximum water content of soil profiles. This will help us understand if the discharge mean of streamflow as it is related to the maximum water content that can be retained before becoming discharge. Seen below:\n\nbaked_data &lt;- prep(rec, camels_train) |&gt;\n  bake(new_data = NULL)\n\nlm_base &lt;- lm(logQmean ~ p_mean * max_water_content, data = baked_data)\n\nsummary(lm_base)\n\n\nCall:\nlm(formula = logQmean ~ p_mean * max_water_content, data = baked_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.70495 -0.31108  0.04349  0.28573  2.06245 \n\nCoefficients:\n                         Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)               -3.2241     0.1451 -22.214  &lt; 2e-16 ***\np_mean                     2.6732     0.1341  19.931  &lt; 2e-16 ***\nmax_water_content         -0.5949     0.1352  -4.400 1.33e-05 ***\np_mean:max_water_content   0.3081     0.1399   2.203   0.0281 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5775 on 498 degrees of freedom\nMultiple R-squared:  0.7668,    Adjusted R-squared:  0.7654 \nF-statistic: 545.9 on 3 and 498 DF,  p-value: &lt; 2.2e-16\n\n\n\ntest_data &lt;- bake(prep(rec), new_data = camels_test)\n\ntest_data$lm_pred &lt;- predict(lm_base, newdata = test_data)\n\nmetrics(test_data, truth = logQmean, estimate = lm_pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.572\n2 rsq     standard       0.746\n3 mae     standard       0.427\n\n\n\n# Defining Random Forest Model\n\nlibrary(baguette)\n\nrf_model &lt;- rand_forest() %&gt;%\n  set_engine(\"ranger\", importance = \"impurity\") %&gt;%\n  set_mode(\"regression\")\n\n\n#Creating and Adding it to the workflow set\nrf_wf &lt;- workflow() %&gt;%\n  add_recipe(rec) %&gt;%\n  add_model(rf_model) %&gt;%\n  fit(data = camels_train)\n\n\nrf_data &lt;- augment(rf_wf, new_data = camels_test)\ndim(rf_data)\n\n[1] 168  60\n\n\n\nmetrics(rf_data, truth = logQmean, estimate = .pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.600\n2 rsq     standard       0.720\n3 mae     standard       0.399\n\n\n\nggplot(rf_data, aes(x = logQmean, y = .pred, color = max_water_content)) +\n  scale_color_viridis_c() +\n  geom_point() +\n  geom_abline() +\n  theme_linedraw()\n\n\n\n\n\n\n\n\n\n# Defining a Linear Regression Model\nlm_model &lt;- linear_reg() %&gt;%\n  set_engine('lm') %&gt;%\n  set_mode(\"regression\")\n\n#Instantiate the workflow:\nlm_wf &lt;- workflow() %&gt;%\n  add_recipe(rec) %&gt;%\n  add_model(lm_model) %&gt;%\n  fit(data = camels_train)\n\nsummary(extract_fit_engine(lm_wf))$coefficients\n\n                             Estimate Std. Error    t value     Pr(&gt;|t|)\n(Intercept)                -3.2240978  0.1451356 -22.214387 1.734810e-76\np_mean                      2.6732285  0.1341254  19.930812 2.022897e-65\nmax_water_content          -0.5949414  0.1352244  -4.399662 1.326996e-05\np_mean_x_max_water_content  0.3080732  0.1398610   2.202709 2.807261e-02\n\n\n\nlm_data &lt;- augment(lm_wf, new_data = camels_test)\n\ndim(lm_data)\n\n[1] 168  61\n\n\n\nmetrics(lm_data, truth = logQmean, estimate = .pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.572\n2 rsq     standard       0.746\n3 mae     standard       0.427\n\nggplot(lm_data, aes(x = logQmean, y = .pred, color = max_water_content)) +\n  scale_color_viridis_c() +\n  geom_point() +\n  geom_abline() +\n  theme_linedraw()\n\n\n\n\n\n\n\n\n\n# Defining a XG Boost Model\n\nb_model &lt;- boost_tree() %&gt;%\n  set_engine('xgboost') %&gt;%\n  set_mode(\"regression\")\n\nb_wf &lt;- workflow() %&gt;%\n  add_recipe(rec) %&gt;%\n  add_model(b_model) %&gt;%\n  fit(data = camels_train)\n\n\nb_data &lt;- augment(b_wf, new_data = camels_test)\ndim(b_data)\n\n[1] 168  60\n\n\n\nmetrics(b_data, truth = logQmean, estimate = .pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.671\n2 rsq     standard       0.662\n3 mae     standard       0.425\n\n\n\n# Checking metrics:\nggplot(b_data, aes(x = logQmean, y = .pred, colour = aridity)) +\n  scale_color_viridis_c() +\n  geom_point() +\n  geom_abline() +\n  theme_linedraw()\n\n\n\n\n\n\n\n\nworkflow set and Evaluating\n\nwf_obj &lt;- workflow_set(list(rec), list(rf_model, lm_model, b_model)) %&gt;%\n  workflow_map('fit_resamples', resamples = camels_cv)\n\nautoplot(wf_obj)\n\n\n\n\n\n\n\n\n\nrank_results(wf_obj, rank_metric = \"rsq\", select_best = TRUE)\n\n# A tibble: 6 × 9\n  wflow_id          .config .metric  mean std_err     n preprocessor model  rank\n  &lt;chr&gt;             &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;        &lt;chr&gt; &lt;int&gt;\n1 recipe_rand_fore… Prepro… rmse    0.566  0.0239    10 recipe       rand…     1\n2 recipe_rand_fore… Prepro… rsq     0.779  0.0191    10 recipe       rand…     1\n3 recipe_linear_reg Prepro… rmse    0.578  0.0248    10 recipe       line…     2\n4 recipe_linear_reg Prepro… rsq     0.766  0.0194    10 recipe       line…     2\n5 recipe_boost_tree Prepro… rmse    0.593  0.0241    10 recipe       boos…     3\n6 recipe_boost_tree Prepro… rsq     0.758  0.0198    10 recipe       boos…     3\n\n\nFor understanding the relationship max water content of soils and precipitation means as they affect discharge mean rates, we should use the random forest model to continue this testing and training of the camels data. Based on the ranking and autoplot the random forest model performs better for understanding the predicted mean streamflow.\n\n# Extract and Evaluate\n\nrf_fit = workflow() |&gt;\n  add_recipe(rec) |&gt;\n  add_model(rf_model) |&gt;\n  fit(camels_train)\n\na = augment(rf_fit, new_data = camels_train)\n\nggplot(a, aes(x = .pred, y = logQmean)) +\n  geom_point()\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\nvip::vip(rf_fit)\n\n\n\n\n\n\n\n\n\nggplot(a, aes(x = logQmean, y = .pred, color = max_water_content)) +\n  scale_color_gradient2(low = \"red\", mid = \"yellow\", high = \"blue2\") +\n  geom_point() +\n  geom_abline(linetype = 2) +\n  theme_linedraw() +\n  labs(title = \"Random Forest Model: Observed vs. Predicted Mean Streamflow\",\n       x = \"Observed Log Mean Flow\",\n       y = \"Predicted Log Mean Flow\",\n       color = \"Max Water Content\")\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nBased on the graph and evaluated workflow for the predicted mean streamflow as it is related to the observed mean streamflow, we can understand that the max water content of the soil profiles and mean precipitation do have a significant influence on streamflow that is seen in the predicted and observed values. Random forest helped us by being able to handle the large data set, while reducing the overfitting of a decision tree to increase it’s accuracy. We can see this in the graph above and the precipiation mean had more importance in relation to mean streamflow discharge. In the beginning of this modelling, we had an R-squared value of 0.7645, understanding that this data was not a successful fit to begin with, responds to how the importance of max water content differs from precipitation mean."
  }
]